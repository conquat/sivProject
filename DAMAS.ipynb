{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to apply acoustic beamforming to locate the source of a sound\n",
    "\n",
    "We will work in a sumilated environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from progressbar import progressbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER_MICROPHONE = np.array([0.0, 0.0, 0.0])\n",
    "TARGET_GRID_CENTER = np.array([0.0, 0.0, 5.0])\n",
    "IMAGE_DIM = (30, 30)\n",
    "scan_plane_size = (8.0, 8.0)\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "SAMPLE_DURATION = 0.2\n",
    "violin = librosa.load('audio/violin_c.wav')[0]\n",
    "white_noise = librosa.load('audio/noise.wav')[0]\n",
    "hz440 = librosa.load('audio/sine_440.wav')[0]\n",
    "hz1000 = librosa.load('audio/sine_1000.mp3')[0]\n",
    "\n",
    "\n",
    "test_points = []\n",
    "for i in range(-int(IMAGE_DIM[1] / 2), int((IMAGE_DIM[1] + 1) / 2)):\n",
    "    for j in range(-int(IMAGE_DIM[0] / 2), int((IMAGE_DIM[0] + 1) / 2)):\n",
    "        test_points.append(TARGET_GRID_CENTER + np.array([\n",
    "            scan_plane_size[0] / (IMAGE_DIM[0] - 1) * j,\n",
    "            scan_plane_size[1] / (IMAGE_DIM[1] - 1) * i,\n",
    "            0.0\n",
    "        ]))\n",
    "\n",
    "def hermite(a):\n",
    "    return np.conj(np.transpose(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array of microphones consists in a grid of uniformly spaced microphones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_microphone_potitions(mic_array_dim, mic_spacing):\n",
    "    microphone_positions = []\n",
    "    for i in range(mic_array_dim[0]):\n",
    "        for j in range(mic_array_dim[1]):\n",
    "            microphone_positions.append(CENTER_MICROPHONE + np.array([\n",
    "                (j - np.floor(mic_array_dim[0] / 2)) * mic_spacing[0],\n",
    "                (i - np.floor(mic_array_dim[1] / 2)) * mic_spacing[1],\n",
    "                0.0\n",
    "            ]))\n",
    "    return microphone_positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The sound pressure recorded at time $t$ by a microphone located at position $x$ produced by a source in $x_0$ is \n",
    "\n",
    "$\\begin{equation} \\tag 1\n",
    "p(x, x_0, t) = \\frac{1}{4\\pi} \\frac{q(x_0, t-t_0)}{\\lvert x - x_0 \\rvert}\n",
    "\\end{equation}$\n",
    "\n",
    "where $t_0$ is the time sound waes take to travel from $x$ to $x_0$\n",
    "\n",
    "$\\begin{equation} \\tag 2\n",
    "t_0 = \\frac{\\lvert x - x_0 \\rvert}{c_0}\n",
    "\\end{equation}$\n",
    "\n",
    "where $c_0$ is the speed of sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOUND_SPEED = 343  # m/s\n",
    "def get_delay(a, b):\n",
    "    return np.linalg.norm(a - b) / SOUND_SPEED\n",
    "\n",
    "\n",
    "def get_recorded_sound(sources, mic_pos, start_time, sample_length):\n",
    "    start_index = int(start_time * SAMPLE_RATE)\n",
    "    sounds = []\n",
    "    for source_position, track in sources:\n",
    "        time_delay = get_delay(TARGET_GRID_CENTER + np.append(source_position, 0.0), mic_pos)\n",
    "        index_delay = int(time_delay * SAMPLE_RATE)\n",
    "        sounds.append(track[start_index + index_delay:start_index + index_delay + sample_length])\n",
    "    received_sound = sum(sounds)\n",
    "    return received_sound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beamforming\n",
    "The first step in the analysis is to beamform over the points we are interested in.\n",
    "\n",
    "##  Delay and sum beamforming\n",
    "\n",
    "This approach consists in anticipating the signal recorded by each microphone by the time sound would take to reach it from the point we are testing.\n",
    "\n",
    "The shifted signals are then summed and the result is divided by the number of microphones in the array. In this way if the sound source corresponds to the point we are testing the waves will produce constructive interference generating an amplified output, otherwise the phase mismatch will cancel the signals and result in a low amplitude output. \n",
    "\n",
    "The output of the beamformer is expressed as\n",
    "\n",
    "$\\begin{equation} \\tag 3\n",
    "Z(t, x_0) = \\frac{4\\pi}{M} \\sum_{m=1}^M \\lvert x - x_0 \\rvert p_m(x_0, t + t_0)\n",
    "\\end{equation}$\n",
    "\n",
    "where $p_m$ if the pressure measured by microphone $m$, $M$ is the number of microphones, $x_0$ is the test position and $x$ is the microphone position.\n",
    "\n",
    "Time domain is simple and computationally fast, but it doesn't allow for post processing deconvolution techniques, for this reason we will use the frequency domain formulation.\n",
    "\n",
    "## Frequency domain formulation\n",
    "The first step of this approach is to compute the fourier transform of the signals received by the microphones.\n",
    "\n",
    "$\\begin{equation} \\tag 4\n",
    "P_m(x, x_0, \\omega) = \\mathscr{F}\\{p(x_0, t)\\} = \\frac{Q(\\omega)e^{-i \\omega t_0}}{4\\pi \\lvert x - x_0 \\rvert}\n",
    "\\end{equation}$\n",
    "\n",
    "The output of the beamformer is now\n",
    "\n",
    "$\\begin{equation} \\tag 5\n",
    "Z(\\omega, x_0) = \\frac{4\\pi}{M} \\sum_{m=1}^M \\lvert x - x_0 \\rvert P(x, x_0, \\omega) e^{i \\omega t_0}\n",
    "\\end{equation}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{equation} \\tag 6\n",
    "s(x, x_0, \\omega) = 4\\pi \\lvert x - x_0 \\rvert e^{i \\omega t_0}\n",
    "\\end{equation}$\n",
    "\n",
    "is called the steering function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrums(sources, microphone_positions, start_time=0.0):\n",
    "    sample_length = int(SAMPLE_DURATION * SAMPLE_RATE)\n",
    "    spectrums = []\n",
    "    for mic_pos in microphone_positions:\n",
    "        recorded_sound = get_recorded_sound(sources, mic_pos, start_time, sample_length)\n",
    "        spectrum = np.fft.fft(recorded_sound) / (4 * np.pi * np.linalg.norm(mic_pos - TARGET_GRID_CENTER))\n",
    "        spectrums.append(spectrum)\n",
    "    return spectrums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a point in the searching grid $x_0$ there is a steering function for each microphone, which are usually summarized in the steering vector\n",
    "\n",
    "\n",
    "$\\begin{equation} \\tag 7\n",
    "  g(x, \\omega) =\n",
    "  \\left(\n",
    "    \\begin{aligned}\n",
    "      & 4\\pi \\lvert x_1 - x_0 \\rvert e^{-i \\omega t_1} \\\\\n",
    "      & 4\\pi \\lvert x_2 - x_0 \\rvert e^{-i \\omega t_2} \\\\\n",
    "\t  & \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\vdots \\notag \\\\\n",
    "\t  & 4\\pi \\lvert x_M - x_0 \\rvert e^{-i \\omega t_M}\n",
    "    \\end{aligned}\n",
    "  \\right)\n",
    "\\end{equation}$\n",
    "\n",
    "The calculations become more convenient if the vector is normalized by the distance between the source and the center of the microphone array, so the normalilzed steering vector is defined as\n",
    "\n",
    "$\\begin{equation} \\tag 8\n",
    "\\hat{e}(x, \\omega) = \\frac{g(x, \\omega)}{\\lvert x_c - x_0 \\rvert}\n",
    "\\end{equation}$\n",
    "\n",
    "The fourier transform of the microphone array can also be represented in vector form\n",
    "\n",
    "$\\begin{equation} \\tag 9\n",
    "Y(\\omega) = \n",
    "\\left(\n",
    "    \\begin{aligned}\n",
    "\t& P_1(\\omega) \\\\\n",
    "\t& P_2(\\omega) \\\\\n",
    "\t& \\;\\;\\;\\;\\;\\vdots \\notag \\\\\n",
    "\t& P_M(\\omega)\n",
    "    \\end{aligned}\n",
    "  \\right)\n",
    "\\end{equation}$\n",
    "\n",
    "In order to make numpy computations faster the steering vectors are grouped into an array that contains one steering vector for each point in the search grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_vector_component(mic_pos, test_pos, frequency):\n",
    "    distance = np.linalg.norm(mic_pos - test_pos)\n",
    "    delay = get_delay(test_pos, mic_pos)\n",
    "    omega = 2 * np.pi * frequency\n",
    "    return 4 * np.pi * distance * np.exp(-1j * omega * delay)\n",
    "\n",
    "def get_steering_vector(test_point, microphone_positions, freq):\n",
    "    steering_vector = np.array(\n",
    "        [\n",
    "            get_steering_vector_component(mic_pos, test_point, freq)\n",
    "            for mic_pos in microphone_positions\n",
    "        ]) / np.linalg.norm(test_point - CENTER_MICROPHONE)\n",
    "    return steering_vector.reshape(len(microphone_positions), 1)\n",
    "\n",
    "def get_steering_vectors(test_points, microphone_positions, freq):\n",
    "    steering_vectors = np.zeros((len(test_points), len(microphone_positions)), dtype=np.complex_)\n",
    "    for i, test_point in enumerate(test_points):\n",
    "        steering_vector = get_steering_vector(test_point, microphone_positions, freq)\n",
    "        steering_vectors[i] = steering_vector.reshape((len(microphone_positions)))\n",
    "    return steering_vectors.reshape(len(test_points), len(microphone_positions), 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the transformer can then be written as the dot product between the two vectors\n",
    "\n",
    "$\\begin{equation} \\tag {10}\n",
    "Z(\\omega) = \\frac{g(x, \\omega)^\\dag Y(\\omega)}{M}\n",
    "\\end{equation}$\n",
    "\n",
    "We are interested in the power output of the beamformer, so\n",
    "\n",
    "$\\begin{equation} \\tag {11}\n",
    "L(x) = ZZ^* = \\frac{g^\\dag(YY^\\dag)g}{M^2}\n",
    "\\end{equation}$\n",
    "\n",
    "The term in the middle of the equation is called the Cross Spectral Matrix\n",
    "\n",
    "$\\begin{equation} \\tag {12}\n",
    "CSM(\\omega) = Y(\\omega)Y(\\omega)^\\dag =\n",
    "\\begin{bmatrix} \n",
    "Y_1Y_1^*           & \\dots         & Y_1Y_M^*         \\\\ \n",
    "\\vdots   &  \\ddots    & \\vdots \\\\\n",
    "Y_MY_1^*           & \\dots         & Y_MY_M^*         \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steering vectors and the CSM are only computed for the frequency we want to scan the grid at. The components of the spectrums we are interested in are extracted from the fourier transforms of the signals received by each microphone ```spectrums``` and put in the ```freq_intensisies``` array, which is used to compute the Cross Spectral Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_intensities(frequency, spectrums):\n",
    "    test_freq_index = int(frequency * SAMPLE_DURATION)\n",
    "    frequency_intensities = np.array([spectrum[test_freq_index] for spectrum in spectrums]).reshape(len(spectrums), 1)\n",
    "    return frequency_intensities\n",
    "\n",
    "def get_csm(frequency_intensities):\n",
    "    return frequency_intensities @ np.conj(np.transpose(frequency_intensities))\n",
    "\n",
    "def get_beamformer_output_power(steering_vectors, csm):\n",
    "    mat = np.zeros((len(steering_vectors)), dtype=np.complex_)\n",
    "    mic_count = len(csm)\n",
    "    for i, steering_vector in enumerate(steering_vectors):\n",
    "        mat[i] = np.take(hermite(steering_vector) @ csm @ steering_vector, 0) / mic_count**2\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example that shows how to get the beamformer power output when a sound source of 1kHz is positioned at coordinates (2.0m, 2.0m) on the searching grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_array_dim = (5, 5)\n",
    "mic_spacing = (0.3, 0.3)\n",
    "\n",
    "microphone_positions = get_microphone_potitions(mic_array_dim, mic_spacing)\n",
    "\n",
    "sources = [\n",
    "    (np.array([2.0, 2.0]), hz1000)\n",
    "]\n",
    "\n",
    "test_freq = 1000\n",
    "\n",
    "spectrums_1_source = get_spectrums(sources, microphone_positions)\n",
    "frequency_intensities = get_frequency_intensities(test_freq, spectrums_1_source)\n",
    "csm = get_csm(frequency_intensities)\n",
    "steering_vectors = get_steering_vectors(test_points, microphone_positions, test_freq)\n",
    "bop_1_source = get_beamformer_output_power(steering_vectors, csm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to show the ```beamformer_output_array``` in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_mat(mat):\n",
    "    im = PIL.Image.new(mode=\"RGB\", size=IMAGE_DIM, color=(0, 0, 0))\n",
    "    mat_abs = abs(mat)\n",
    "    norm = 255 / max(mat_abs)\n",
    "    for i in range(IMAGE_DIM[1]):\n",
    "        for j in range(IMAGE_DIM[0]):\n",
    "            val = mat_abs[i * IMAGE_DIM[1] + IMAGE_DIM[0] - j - 1] * norm\n",
    "            im.putpixel((j, i), (0, 0, int(val)))\n",
    "    display(im.resize((500, 500), resample=PIL.Image.Resampling.NEAREST))\n",
    "\n",
    "show_mat(bop_1_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same with 2 sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    (np.array([2.0, -1.0]), hz1000),\n",
    "    (np.array([-2.0, -2.0]), hz1000),\n",
    "]\n",
    "\n",
    "spectrums_2_sources = get_spectrums(sources, microphone_positions)\n",
    "frequency_intensities = get_frequency_intensities(test_freq, spectrums_2_sources)\n",
    "csm = get_csm(frequency_intensities)\n",
    "steering_vectors = get_steering_vectors(test_points, microphone_positions, test_freq)\n",
    "bop_2_sources = get_beamformer_output_power(steering_vectors, csm)\n",
    "\n",
    "show_mat(bop_2_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one source will produce a sound at 1KHz, the other at 440Hz.\n",
    "\n",
    "Looking for 1KHz sound sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    (np.array([2.0, -1.0]), hz1000),\n",
    "    (np.array([-2.0, -2.0]), hz440),\n",
    "]\n",
    "\n",
    "test_freq = 1000\n",
    "\n",
    "spectrums_2_sources = get_spectrums(sources, microphone_positions)\n",
    "frequency_intensities = get_frequency_intensities(test_freq, spectrums_2_sources)\n",
    "csm = get_csm(frequency_intensities)\n",
    "steering_vectors = get_steering_vectors(test_points, microphone_positions, test_freq)\n",
    "bop_2_sources_diff_freq = get_beamformer_output_power(steering_vectors, csm)\n",
    "\n",
    "show_mat(bop_2_sources_diff_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for 440Hz sound sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_freq = 440\n",
    "\n",
    "frequency_intensities = get_frequency_intensities(test_freq, spectrums_2_sources)\n",
    "csm = get_csm(frequency_intensities)\n",
    "steering_vectors = get_steering_vectors(test_points, microphone_positions, test_freq)\n",
    "bop_2_sources_diff_freq = get_beamformer_output_power(steering_vectors, csm)\n",
    "\n",
    "show_mat(bop_2_sources_diff_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with a denser microphone array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_array_dim = (11, 11)\n",
    "mic_spacing = (0.15, 0.15)\n",
    "\n",
    "microphone_positions = get_microphone_potitions(mic_array_dim, mic_spacing)\n",
    "\n",
    "sources = [\n",
    "    (np.array([2.0, -1.0]), hz1000),\n",
    "    (np.array([-2.0, -2.0]), hz1000),\n",
    "]\n",
    "\n",
    "test_freq = 1000\n",
    "\n",
    "spectrums_2_sources = get_spectrums(sources, microphone_positions)\n",
    "frequency_intensities = get_frequency_intensities(test_freq, spectrums_2_sources)\n",
    "csm = get_csm(frequency_intensities)\n",
    "steering_vectors = get_steering_vectors(test_points, microphone_positions, test_freq)\n",
    "bop_2_sources_denser = get_beamformer_output_power(steering_vectors, csm)\n",
    "\n",
    "show_mat(bop_2_sources)\n",
    "show_mat(bop_2_sources_denser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's evident that the spatial resolution of this technique is not great and the sources look spread out, this effect is reduced by increasing the density of the microphone array.\n",
    "\n",
    "The microphone array is acting as a spatial filter, the properties of this filter determine its point spread function, which determines how it respondes to a point source placed in front of the array. An ideal array would respond producing an infinitesimally small point, but that device is practically impossible because it should be have a spatially continuous distribution of sensors.\n",
    "\n",
    "In real application the beamformer output is convolved with the array transfer function, producing a \"dirty map\".\n",
    "\n",
    "In order to obtain better results deconvolution techniques can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution technique\n",
    "## DAMAS\n",
    "One technique to reduce the unwanted artefacts is the Deconvolution Approach for the Mapping of Acoustic Sources (DAMAS).\n",
    "\n",
    "In this approach we start considering the signal that a microphone placed at the center of the array would receive if a sound would be produced by the source $n$ of the searching grid.\n",
    "\n",
    "$\\begin{equation} \\tag {13}\n",
    "P(\\omega) = Q_n(\\omega)e_{m:n}^{-1}(x, \\omega)\n",
    "\\end{equation}$\n",
    "\n",
    "The power of the signal would be written as\n",
    "\n",
    "$\\begin{equation} \\tag {15}\n",
    "P_{m:n}(\\omega)P_{m:n}^*(\\omega) =\n",
    "(Q_n(\\omega)e_{m:n}^{-1}(x, \\omega))^*(Q_n(\\omega)e_{m:n}^{-1}(x, \\omega)) = \n",
    "Q_n(\\omega) Q_n^*(\\omega) (e_{m:n}^{-1}(x, \\omega))^* (e_{m:n}^{-1}(x, \\omega))\n",
    "\\end{equation}$\n",
    "\n",
    "The modeled Cross Spectral Martix of the signal that the microphone would receive is\n",
    "\n",
    "$\\begin{equation} \\tag {16}\n",
    "CSM^{mod}_n(\\omega) = X_n\n",
    "\\begin{bmatrix} \n",
    "(e_1^{-1})^*(e_1^{-1})           & \\dots         & (e_1^{-1})^*(e_M^{-1})         \\\\ \n",
    "\\vdots                           & \\ddots        & \\vdots                         \\\\\n",
    "(e_M^{-1})^*(e_1^{-1})           & \\dots         & (e_M^{-1})^*(e_M^{-1})         \\\\\n",
    "\\end{bmatrix}_n\n",
    "\\end{equation}$\n",
    "\n",
    "Where $X_n$ is the power-spectral density contribution of a source located at the grid position $n$.\n",
    "\n",
    "Considering that the the sources placed on the search grid are independent, the modeled CSM can be computed summing all the contributions of the single sources.\n",
    "$\\begin{equation} \\tag {17}\n",
    "CSM^{mod}(\\omega) = \\sum_{n=1}^N CSM^{mod}_n(\\omega)\n",
    "\\end{equation}$\n",
    "\n",
    "The modeled power output of the beamformer can now be computed as before:\n",
    "\n",
    "$\\begin{equation} \\tag {18}\n",
    "L^{mod}_n = \\frac{\\hat{e}_n^T CSM^{mod}(\\omega) \\hat{e}_n}{M^2} = \\frac{\\hat{e}_n^T \\sum_{k=1}^N X_k[]_k \\hat{e}_n}{M^2} = \\sum_{k=1}^N \\frac{\\hat{e}_n^T []_k \\hat{e}_n}{M^2}X_k = \n",
    "\\end{equation}$\n",
    "\n",
    "where the bracketed term is the cross inverse steering vector matrix of equation 16.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cisvm_mods(inv_steering_vectors):\n",
    "    cisvm_mods = np.conjugate(inv_steering_vectors) @ inv_steering_vectors.reshape(len(inv_steering_vectors), 1, len(microphone_positions))\n",
    "    return cisvm_mods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modeled output power of the beamformer can be further summarized as:\n",
    "$\\begin{equation} \\tag {19}\n",
    "L^{mod}_n = \\sum_{k=1}^N A_{nk} X_k\n",
    "\\end{equation}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{equation} \\tag {20}\n",
    "A_{nk} = \\frac{\\hat{e}_n^T []_k \\hat{e}_n}{M^2}\n",
    "\\end{equation}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A_mat(steering_vectors):\n",
    "    inv_steering_vectors = np.reciprocal(steering_vectors)\n",
    "    mat = np.zeros((len(steering_vectors), len(steering_vectors)), dtype=np.complex_)\n",
    "    cisvm_mods = get_cisvm_mods(inv_steering_vectors)\n",
    "    for i, steering_vector in enumerate(progressbar(steering_vectors)):\n",
    "        for j, csvm_mod in enumerate(cisvm_mods):\n",
    "            mat[i, j] = np.take(hermite(steering_vector) @ csvm_mod @ steering_vector, 0) / len(csvm_mod)**2\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now equate the modeled output power with the one obtained from measured data obtaining a system of linear equations:\n",
    "$\\begin{equation} \\tag {21}\n",
    "\\hat{Y} = \\hat{A}\\hat{X}\n",
    "\\end{equation}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{equation} \\tag {22}\n",
    "\\hat{Y} =\n",
    "\\left(\n",
    "    \\begin{aligned}\n",
    "      & L_1 \\\\\n",
    "      & L_2 \\\\\n",
    "      & \\;\\;\\vdots \\notag \\\\\n",
    "      & L_N\n",
    "    \\end{aligned}\n",
    "  \\right)\n",
    "\\end{equation}$\n",
    "\n",
    "$\\begin{equation} \\tag {23}\n",
    "\\hat{A} =\n",
    "\\begin{bmatrix} \n",
    "A_{11}           & \\dots         & A_{1N}         \\\\ \n",
    "\\vdots           & \\ddots        & \\vdots         \\\\\n",
    "A_{N1}           & \\dots         & A_{NN}         \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}$\n",
    "\n",
    "$\\begin{equation} \\tag {24}\n",
    "\\hat{X} =\n",
    "\\left(\n",
    "    \\begin{aligned}\n",
    "      & X_1 \\\\\n",
    "      & X_2 \\\\\n",
    "      & \\;\\;\\vdots \\notag \\\\\n",
    "      & X_N\n",
    "    \\end{aligned}\n",
    "  \\right)\n",
    "\\end{equation}$\n",
    "\n",
    "The $\\hat{A}$ matrix is usually singular, so it can't be inverted. The problem can be solved using an iterative method.\n",
    "\n",
    "A single equation of the system can be written in the form\n",
    "$\\begin{equation} \\tag {25}\n",
    "A_{n1}X_1 + \\dots + A_{nk}A_k + \\dots + A_{nN}X_N = Y_n\n",
    "\\end{equation}$\n",
    "\n",
    "The term $A_{nn}$ is equal to\n",
    "\n",
    "$\\begin{equation} \\tag {26}\n",
    "A_{nn} = \\frac{\n",
    "\\hat{e}_n^T\n",
    "\\begin{bmatrix} \n",
    "  (e_1^{-1})^*(e_1^{-1})           & \\dots         & (e_1^{-1})^*(e_M^{-1})         \\\\ \n",
    "  \\vdots                           & \\ddots        & \\vdots                         \\\\\n",
    "  (e_M^{-1})^*(e_1^{-1})           & \\dots         & (e_M^{-1})^*(e_M^{-1})         \\\\\n",
    "\\end{bmatrix}_n\n",
    "\\hat{e}_n\n",
    "}{M^2} = 1\n",
    "\\end{equation}$\n",
    "\n",
    "so the equation can be rewritten as:\n",
    "\n",
    "$\\begin{equation} \\tag {27}\n",
    "X_n = Y_n - \\left[ \\sum_{k=1}^{n-1} A_{nk}X_k + \\sum_{k=n+1}^N A_{nk}X_k \\right]\n",
    "\\end{equation}$\n",
    "\n",
    "The system of equation can now be solved iterating these steps:\n",
    "\n",
    "$\\begin{equation}  \\tag {28}\n",
    "X_1^{(i)} = Y_1 - \\left[ 0 + \\sum_{k=1+1}^N A_{1k}X_k^{(i-1)} \\right]\n",
    "\\end{equation}$\n",
    "\n",
    "$\\begin{equation} \\tag {29}\n",
    "X_n^{(i)} = Y_n - \\left[ \\sum_{k=1}^{n-1} A_{nk}X_k^{(i)} + \\sum_{k=n+1}^N A_{nk}X_k^{(i - 1)} \\right]\n",
    "\\end{equation}$\n",
    "\n",
    "$\\begin{equation} \\tag {30}\n",
    "X_N^{(i)} = Y_N - \\left[ \\sum_{k=1}^{N-1} A_{Nk}X_k^{(i)} + 0 \\right]\n",
    "\\end{equation}$\n",
    "\n",
    "The componentes of $\\hat{X}$ are initialized to $0$ and since the strength sound sources is non-negative, the minimim of each component is clamped to $0$. An iteration consists in the computation of $X_i$ following first the order $1 \\dots N$ and then $N \\dots 1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAMAS_iteration(a_mat, x_mat, y_mat, n):\n",
    "    sum_1 = 0\n",
    "    for k in range(0, n):\n",
    "        f1 = a_mat[n, k]\n",
    "        f2 = x_mat[k]\n",
    "        sum_1 += f1 * f2\n",
    "\n",
    "    sum_2 = 0\n",
    "    for k in range(n+1, len(x_mat)):\n",
    "        f1 = a_mat[n, k]\n",
    "        f2 = x_mat[k]\n",
    "        sum_2 += f1 * f2\n",
    "    x_mat[n] = max(y_mat[n] - (np.take(sum_1, 0) + np.take(sum_2, 0)), 0)\n",
    "\n",
    "\n",
    "def DAMAS(beamformer_output_power, steering_vectors, a_mat, n_iterations):\n",
    "    x_mat = np.zeros((len(steering_vectors)), dtype=np.complex_)\n",
    "    for _ in progressbar(range(n_iterations)):\n",
    "        for n in range(len(x_mat)):\n",
    "            DAMAS_iteration(a_mat, x_mat, beamformer_output_power, n)\n",
    "        for n in range(len(x_mat) - 1, -1, -1):\n",
    "            DAMAS_iteration(a_mat, x_mat, beamformer_output_power, n)\n",
    "    return x_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the result of the DAMAS algorithm with 10 and 50 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_array_dim = (5, 5)\n",
    "mic_spacing = (0.3, 0.3)\n",
    "\n",
    "microphone_positions = get_microphone_potitions(mic_array_dim, mic_spacing)\n",
    "\n",
    "sources = [\n",
    "    (np.array([2.0, 2.0]), hz1000)\n",
    "]\n",
    "\n",
    "test_freq = 1000\n",
    "\n",
    "spectrums_1_source = get_spectrums(sources, microphone_positions)\n",
    "frequency_intensities = get_frequency_intensities(test_freq, spectrums_1_source)\n",
    "csm = get_csm(frequency_intensities)\n",
    "steering_vectors = get_steering_vectors(test_points, microphone_positions, test_freq)\n",
    "bop_1_source = get_beamformer_output_power(steering_vectors, csm)\n",
    "\n",
    "a_mat = get_A_mat(steering_vectors)\n",
    "\n",
    "x_mat_10 = DAMAS(bop_1_source, steering_vectors, a_mat, 5)\n",
    "x_mat_20 = DAMAS(bop_1_source, steering_vectors, a_mat, 50)\n",
    "show_mat(bop_1_source)\n",
    "show_mat(x_mat_10)\n",
    "show_mat(x_mat_20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the result of the DAMAS algorithm with 100 iterations on 2 sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_array_dim = (5, 5)\n",
    "mic_spacing = (0.3, 0.3)\n",
    "\n",
    "microphone_positions = get_microphone_potitions(mic_array_dim, mic_spacing)\n",
    "\n",
    "sources = [\n",
    "    (np.array([2.0, 1.0]), hz1000),\n",
    "    (np.array([-2.0, -2.0]), hz1000)\n",
    "]\n",
    "\n",
    "test_freq = 1000\n",
    "\n",
    "spectrums_2_sources = get_spectrums(sources, microphone_positions)\n",
    "frequency_intensities = get_frequency_intensities(test_freq, spectrums_2_sources)\n",
    "csm = get_csm(frequency_intensities)\n",
    "steering_vectors = get_steering_vectors(test_points, microphone_positions, test_freq)\n",
    "bop_2_sources = get_beamformer_output_power(steering_vectors, csm)\n",
    "\n",
    "\n",
    "x_mat = DAMAS(bop_2_sources, steering_vectors, a_mat, 100)\n",
    "show_mat(bop_2_sources)\n",
    "show_mat(x_mat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
